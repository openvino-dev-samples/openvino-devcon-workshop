{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebe1155a-9e14-4c47-bccb-fdb1f2604def",
   "metadata": {},
   "source": [
    "# Lab 1. Text-completion with GenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2ea3b7-4e7b-4782-b35d-50fb4576ad8d",
   "metadata": {},
   "source": [
    "### ### Download LLM model from ModelScope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7d35c93-6341-4422-a41f-ea084d597579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading [added_tokens.json]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 80.0/80.0 [00:00<00:00, 122B/s]\n",
      "Downloading [config.json]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 677/677 [00:00<00:00, 893B/s]\n",
      "Downloading [generation_config.json]: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 243/243 [00:01<00:00, 132B/s]\n",
      "Downloading [merges.txt]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.59M/1.59M [00:01<00:00, 1.02MB/s]\n",
      "Downloading [openvino_detokenizer.bin]: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.88M/1.88M [00:00<00:00, 2.28MB/s]\n",
      "Downloading [openvino_detokenizer.xml]: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.95k/4.95k [00:00<00:00, 6.64kB/s]\n",
      "Downloading [openvino_model.bin]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.81G/4.81G [00:48<00:00, 107MB/s]\n",
      "Downloading [openvino_model.xml]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3.20M/3.20M [00:02<00:00, 1.63MB/s]\n",
      "Downloading [openvino_tokenizer.bin]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3.91M/3.91M [00:01<00:00, 4.05MB/s]\n",
      "Downloading [openvino_tokenizer.xml]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26.3k/26.3k [00:00<00:00, 29.7kB/s]\n",
      "Downloading [special_tokens_map.json]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 367/367 [00:00<00:00, 421B/s]\n",
      "Downloading [tokenizer.json]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6.70M/6.70M [00:02<00:00, 3.12MB/s]\n",
      "Downloading [tokenizer_config.json]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.27k/1.27k [00:00<00:00, 1.72kB/s]\n",
      "Downloading [vocab.json]: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.65M/2.65M [00:01<00:00, 1.44MB/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from modelscope import snapshot_download\n",
    "\n",
    "llm_model_id = \"snake7gun/Qwen2-7B-Instruct-int4-ov\"\n",
    "llm_local_path  = \"./model/\" + llm_model_id\n",
    "\n",
    "if not Path(llm_local_path).exists():\n",
    "    model_dir = snapshot_download(llm_model_id, cache_dir=\"./model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49e8764-25a6-4d42-8a8e-30e0db792199",
   "metadata": {},
   "source": [
    "### Initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83ebf4f1-a5b3-4c9a-a98f-bc885ebf6549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino_genai as ov_genai\n",
    "\n",
    "pipe = ov_genai.LLMPipeline(llm_local_path, \"GPU\")\n",
    "\n",
    "def streamer(subword):\n",
    "    print(subword, end='', flush=True)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f06970-6bc2-4e50-85fe-cc49c35c31dd",
   "metadata": {},
   "source": [
    "### Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ef4d999-04c7-4b1a-ad42-1b2e6cdc4bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenVINO（Open Visual Inference and Neural Network Optimization）是由英特尔开发的一套开源工具套件，用于在各种设备上部署深度学习模型。它提供了一个API库和一组工具，用于优化神经网络模型的性能，并在不同的硬件平台上进行推理。\n",
      "\n",
      "OpenVINO的主要功能包括：\n",
      "\n",
      "1. **模型优化**：它能够优化神经网络模型，以适应不同的硬件平台，包括CPU、GPU、VPU（Vision Processing Unit）等。优化过程包括模型转换、量化、并行化等步骤，以提高模型的执行效率。\n",
      "\n",
      "2. **推理引擎**：OpenVINO提供了一个高性能的推理引擎，用于在各种硬件平台上执行模型推理。它支持多种硬件加速技术，如OpenCL、VPU等，以实现快速的实时推理。\n",
      "\n",
      "3. **API支持**：它提供了多种编程语言的API接口，如C++、Python等，方便开发者在不同的开发环境中使用。\n",
      "\n",
      "4. **模型库**：OpenVINO还包含了一些预训练的模型库，开发者可以直接使用这些模型进行特定任务的开发，而无需从头开始训练模型。\n",
      "\n",
      "5. **支持多种框架**：它支持多种深度学习框架，如TensorFlow、Caffe、ONNX等，使得开发者可以方便地将模型从这些框架转换到OpenVINO进行优化和部署。\n",
      "\n",
      "通过使用OpenVINO，开发者可以更高效地将深度学习模型部署到实际应用中，特别是在需要在边缘设备上进行实时推理的场景中。"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OpenVINO（Open Visual Inference and Neural Network Optimization）是由英特尔开发的一套开源工具套件，用于在各种设备上部署深度学习模型。它提供了一个API库和一组工具，用于优化神经网络模型的性能，并在不同的硬件平台上进行推理。\\n\\nOpenVINO的主要功能包括：\\n\\n1. **模型优化**：它能够优化神经网络模型，以适应不同的硬件平台，包括CPU、GPU、VPU（Vision Processing Unit）等。优化过程包括模型转换、量化、并行化等步骤，以提高模型的执行效率。\\n\\n2. **推理引擎**：OpenVINO提供了一个高性能的推理引擎，用于在各种硬件平台上执行模型推理。它支持多种硬件加速技术，如OpenCL、VPU等，以实现快速的实时推理。\\n\\n3. **API支持**：它提供了多种编程语言的API接口，如C++、Python等，方便开发者在不同的开发环境中使用。\\n\\n4. **模型库**：OpenVINO还包含了一些预训练的模型库，开发者可以直接使用这些模型进行特定任务的开发，而无需从头开始训练模型。\\n\\n5. **支持多种框架**：它支持多种深度学习框架，如TensorFlow、Caffe、ONNX等，使得开发者可以方便地将模型从这些框架转换到OpenVINO进行优化和部署。\\n\\n通过使用OpenVINO，开发者可以更高效地将深度学习模型部署到实际应用中，特别是在需要在边缘设备上进行实时推理的场景中。'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"<|im_start|>system\\n<|im_end|>\\n<|im_start|>user\\n什么是OpenVINO？<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "pipe.generate(prompt, eos_token_id=151645, max_length=500, streamer=streamer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
